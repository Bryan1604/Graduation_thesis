version: '3'

services:
  spark-master:
    container_name: spark-master
    build: .
    image: bitnami/spark:latest
    entrypoint: ['./entrypoint.sh', 'master']
    healthcheck:
      test: ["CMD","curl","-f", "http://localhost:8080"]
      interval: 5s
      timeout: 3s
      retries: 3
    volumes:
      - ./data:/opt/spark/data
      - ./spark_apps:/opt/spark/apps
      - spark-logs:/opt/spark/spark_version
    env_file:
      - .env.spark
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "9090:8080" #9090 ui
      - "7077:7077"  # complicate with worker, server-to-server master
    networks:
      - confluent

  spark-history-server:
    container_name: spark-history
    image: bitnami/spark:latest
    entrypoint: ['./entrypoint.sh', 'history']
    depends_on: 
      - spark-master 
    env_file:
      - .env.spark
    volumes:
      - spark-logs:/opt/spark/sparl_events
    ports:
      - "18080:18080" 
  
  spark-worker:
    image: bitnami/spark:latest
    # command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on: 
      - spark-master 
    env_file:
      - .env.spark
    volumes:
      - ./data:/opt/spark/data
      - ./spark_apps:/opt/spark/apps
      - spark-logs:/opt/spark/spark_version
      
  volumes:
    spark-logs: