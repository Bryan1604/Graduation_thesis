version: '3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test:
        [
          'CMD',
          'bash',
          '-c',
          "echo 'ruok' | nc localhost 2181"
        ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - confluent

  # broker:
  #   image: confluentinc/cp-server:latest
  #   hostname: broker
  #   container_name: broker
  #   depends_on:
  #     zookeeper:
  #       condition: service_healthy
  #   ports:
  #     - "29092:9092"
  #     - "9101:9101"
  #   environment:
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
  #     KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
  #     KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
  #     KAFKA_JMX_PORT: 9101
  #     KAFKA_JMX_HOSTNAME: localhost
  #     KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
  #     CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
  #     CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
  #     CONFLUENT_METRICS_ENABLE: 'false'
  #     CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
  #   networks:
  #     - confluent
  #   healthcheck:
  #     test: [ "CMD", "bash", "-c", 'nc -z localhost 9092' ]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5

  kafka1:
    container_name: kafka1
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
    networks:
      - confluent
    healthcheck:
      test: [ "CMD", "bash", "-c", 'nc -z localhost 9092' ]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka2:
    container_name: kafka2
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - 29093:29093
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9093,PLAINTEXT_HOST://localhost:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
    networks:
      - confluent


  scala-stream-collector:
    container_name: collector
    image: snowplow/scala-stream-collector-kafka:3.1.0
    command: [ "--config", "/snowplow/config.hocon" ]
    depends_on:
      - kafka1
    ports:
      - "8080:8080"
    volumes:
      - ./snowplow/collector-config:/snowplow/
    networks:
      - confluent

  stream-enrich:
    container_name: enrich
    image: snowplow/snowplow-enrich-kafka:3.8.0
    command:
      [
        "--config",
        "/snowplow/config.hocon",
        "--iglu-config",
        "/snowplow/resolver.json",
        "--enrichments",
        "/snowplow/enrichments"
      ]
    depends_on:
      - scala-stream-collector
    volumes:
      - ./snowplow/enrich-config:/snowplow
    networks:
      - confluent

  # db cho iglu server
  postgresdb:
    image: postgres
    container_name: my-postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: igludb
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: snowplow
    volumes:
      - ./snowplow/iglu-server-config/init.sql:/docker-entrypoint-initdb.d/init.sql
      - ./snowplow/postgres-data:/var/lib/postgresql@14/data
    networks:
      - confluent

  iglu-server:
    container_name: iglu-server
    image: snowplow/iglu-server:0.10.0
    depends_on:
      - postgresdb
    ports:
      - "8181:8181"
    volumes:
      - ./snowplow/iglu-server-config:/iglu
    command: "--config /iglu/config.hocon"
    networks:
      - confluent

  # schema-registry:
  #   image: confluentinc/cp-schema-registry:latest
  #   hostname: schema-registry
  #   container_name: schema-registry
  #   depends_on:
  #     kafka1:
  #       condition: service_healthy
  #   ports:
  #     - "8081:8081"
  #   environment:
  #     SCHEMA_REGISTRY_HOST_NAME: schema-registry
  #     SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka1:29092'
  #     SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
  #   networks:
  #     - confluent
  #   healthcheck:
  #     test: [ "CMD", "curl", "-f", "http://localhost:8081/" ]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5

  # control-center:
  #   image: confluentinc/cp-enterprise-control-center:latest
  #   hostname: control-center
  #   container_name: control-center
  #   depends_on:
  #     kafka1:
  #       condition: service_healthy
  #     schema-registry:
  #       condition: service_healthy
  #   ports:
  #     - "9021:9021"
  #   environment:
  #     CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka1:29092'
  #     CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
  #     CONTROL_CENTER_REPLICATION_FACTOR: 1
  #     CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
  #     CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
  #     CONFLUENT_METRICS_TOPIC_REPLICATION: 1
  #     CONFLIENT_METRICS_ENABLE: 'false'
  #     PORT: 9021
  #   networks:
  #     - confluent
  #   healthcheck:
  #     test: [ "CMD", "curl", "-f", "http://localhost:9021/health" ]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5

  #khoi tao database cho customer data -> co thể khoong cần -> su dụng luôn mysql
  # postgres:
  #   image: postgres:latest
  #   restart: always
  #   environment:
  #     POSTGRES_USER: admin
  #     POSTGRES_PASSWORD: admin
  #     POSTGRES_DB: cdp
  #   ports:
  #     - "5432:5432"
  #   volumes:
  #     - ./pgdata:/var/lib/postgresql/data
  
  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    command: bin/spark-class org.apache.spark.deploy.master.Master
    build:
      context: ./spark
      dockerfile: Dockerfile
    ports:
      - "9090:8080" #9090 ui
      - "7077:7077"  # complicate with worker, server-to-server master
    networks:
      - confluent

  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker
    command: bash -c "/opt/bitnami/spark/bin/spark-submit --master spark://spark-master:7077 /app/spark_streaming.py"
    build: 
      context: ./spark
      dockerfile: Dockerfile
    depends_on: 
      - spark-master 
    environment: 
      SPARK_MODE: worker 
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g 
      SPARK_MASTER_URL: spark://spark-master:7077
    networks:
      - confluent 
    # hostname: my-spark-worker
    volumes:
      - ./spark:/app
  
  #elastic search 
  elasticsearch:
    image: elasticsearch:8.13.0
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      - cluster.name=streaming_event
      - node.name=elasticsearch   # 1 node trên cluster
      - discovery.type=single-node
      - xpack.security.enabled=false
    volumes:
      - ./data:/var/lib/elasticsearch/data
    # command: >
    #   bash -c '
    #     sleep 10
    #     until curl -sS "http://localhost:9200/_cat/health?h=status" | grep -q "green\|yellow"; do
    #      sleep 30
    #     done
    #     curl -X PUT "http://localhost:9200/event_streaming" -H "Content-Type: application/json" -d'
    #     {
    #       "mappings": {
    #         "properties": {
    #           "event_id" : { "type" : "text" },
    #           "time" : { "type" : "text" },
    #           "user_id" : { "type" : "text" },
    #           "user_name" : { "type" : "text" },
    #           "phone_number" : { "type" : "text" },
    #           "email" : { "type" : "text" },
    #           "event_type" : { "type" : "text" },
    #           "domain_userid" : { "type" : "text" },
    #           "products" : {
    #             "properties" : {
    #               "product_id" : { "type" : "text" },
    #               "product_name" : { "type" : "text" },
    #               "price" : { "type" : "integer" },
    #               "quantity" : { "type" : "text" },
    #               "size" : { "type" : "text" },
    #               "category" : { "type" : "text" }
    #             }
    #         }
    #       }
    #     }'
    #   '
    networks:
      - confluent

  db:
    image: mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: 12345678
      MYSQL_DATABASE: CDP
      # MYSQL_USER: root
      # MYSQL_PASSWORD: 12345678
    ports:
      - "3306:3306"
    volumes:
      - ./data:/var/lib/mysql
networks:
  confluent:

